[源码解析] 模型并行分布式训练Megatron (1) --- 论文 & 基础
https://www.cnblogs.com/rossiXYZ/p/15840803.html

[源码解析] 模型并行分布式训练Megatron (2) --- 整体架构
https://www.cnblogs.com/rossiXYZ/p/15868988.html

[源码解析] 模型并行分布式训练 Megatron (3) ---模型并行实现
https://www.cnblogs.com/rossiXYZ/p/15871062.html

[源码解析] 模型并行分布式训练 Megatron (4) --- 如何设置各种并行
https://www.cnblogs.com/rossiXYZ/p/15876714.html

模型并行分布式训练Megatron (5) --Pipedream Flush
https://www.cnblogs.com/rossiXYZ/p/15890482.html


！！！https://github.com/ProjectD-AI/LLaMA-Megatron-DeepSpeed

Megatron-LM源码阅读（一）
https://zhuanlan.zhihu.com/p/405883984
Megatron-LM源码阅读（二）
https://zhuanlan.zhihu.com/p/407094090

----
简枫
深入理解 Megatron-LM（1）基础知识
深入理解 Megatron-LM（2）原理介绍
深入理解 Megatron-LM（3）代码结构
深入理解 Megatron-LM（4）模型并行
深入理解 Megatron-LM（5）并行设置
---以上抄袭多，干货少
Megatron-LM 近期的改动  https://zhuanlan.zhihu.com/p/651192295

Megatron-LM 最新 release 的版本是 23.06：

https://github.com/NVIDIA/Megatron-LM/tree/23.06/megatron​github.com/NVIDIA/Megatron-LM/tree/23.06/megatron
​github.com/NVIDIA/Megatron-LM/tree/23.06/megatron
相比之前的版本，有几个比较重大的更新，如下：

增加了对 Rotary Positional Embedding 的支持。
增加了对 FlashAttention v1 和 v2 的支持。
在Zero并行的情况下（distributed-optimizer），增加了一些新的细粒度 partial checkpointing 的技术。
修复了模型的 Checkpoint 保存/加载相关的问题。
Megatron-LM 中的 GPT 模型的流水线并行实现进行了重大重构。
其中，细粒度 partial checkpointing 的技术，体现在：

只要模型Checkpoint的流水线并行组（PP）和张量并行组（TP）不变，就可以动态加载并且继续训练模型，即使数据并行组（DP）的个数发生变化。

因为
总
数
 ，在大模型的训练过程中，会经常遇到GPU或者Node突然坏掉的情况，所以整体的GPU总数可能是动态变化的。这样新特性的支持可以更方便的让我们在有个别GPU或者Node坏掉的情况下重启训练过程。

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



深度学习里，模型并行中怎么将模型拆分？图解张量模型并行(TP)，Megatron-LM
http://www.python88.com/topic/156151

简单三步看清Megatron-LM的实现, Megatron源码解析
https://66ring.github.io/2023/07/02/universe/ml/megatron_three_easy_pieces/


How to train a Language Model with Megatron-LM
https://huggingface.co/blog/megatron-training

深度学习里，模型并行中怎么将模型拆分？图解张量模型并行(TP)，Megatron-LM
http://www.python88.com/topic/156151

DeepSpeed结合Megatron-LM训练GPT2模型笔记上
BBuf

DeepSpeed结合Megatron-LM训练GPT2模型笔记上/


https://www.yuanjisong.com/job/107638
分析nvidia Megatron-LM分布式训练代码
合作方式：项目制 全国远程
预估日薪：1000
预估总价：20000元
预估工时：20天
